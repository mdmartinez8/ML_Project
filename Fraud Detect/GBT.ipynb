{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b165588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb1c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "  return pd.read_csv(filename)\n",
    "\n",
    "def avg_trans_amt_per_card(data):\n",
    "    # Average Transaction Amount Per Card: Used to calculate the average amount of money \n",
    "    # spent in transactions for each credit card in the dataset. Once we have the average we \n",
    "    # will use it to compare each transaction amount to the average, and can help identify \n",
    "    # transactions that are too high.\n",
    "    # Group by credit card number and calculate the mean transaction amount\n",
    "    average_amt_per_card = data.groupby('cc_num')['amt'].mean().reset_index()\n",
    "    average_amt_per_card.rename(columns={'amt': 'avg_amt_per_card'}, inplace=True)\n",
    "    # Merge the average transaction amount per card back to both the train and test datasets\n",
    "    data = data.merge(average_amt_per_card, on='cc_num', how='left')\n",
    "    # Create a new column to compare transaction amount to the average per card\n",
    "    data['amt_vs_avg'] = data['amt'] / data['avg_amt_per_card']\n",
    "    return data\n",
    "\n",
    "def trans_freq_per_card(data):\n",
    "    # Transaction Frequency Per Card: Used to count how many transactions are made each \n",
    "    # day per credit card. Helps detect unusual activity if there are more transactions per \n",
    "    # day than the usual pattern.\n",
    "    # Calculate transaction frequency per card per day\n",
    "    trans_freq_per_card = data.groupby(['cc_num', 'trans_date']).size().reset_index(name='trans_freq_per_day')\n",
    "    data = data.merge(trans_freq_per_card, on=['cc_num', 'trans_date'], how='left')\n",
    "    return data\n",
    "\n",
    "def change_in_spending(data):\n",
    "    # Change in Spending Pattern Per Card: Used to compare the current transaction amount to the average\n",
    "    # amount spent for a similar category. By detecting significant deviations in spending patters per \n",
    "    # category we can detect fraud.\n",
    "    # Calculate average spending per card per category\n",
    "    avg_spending_per_card_category = data.groupby(['cc_num', 'category'])['amt'].transform('mean')\n",
    "    data['change_in_spending'] = data['amt'] / avg_spending_per_card_category\n",
    "    return data\n",
    "\n",
    "def handle_date_time(data):\n",
    "    # Converting trans_date_trans_time into a datetime object, then making new cols: trans_date and trans_time\n",
    "    data['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'], format='%m/%d/%y %H:%M') # converting the 'trans_date_trans_time' column from a string to a datetime object \n",
    "    data['trans_date'] = data['trans_date_trans_time'].dt.date # extracts the date part from the 'trans_date_trans_time' datetime object and stores it in a new column called 'trans_date'.\n",
    "    data['trans_time'] = data['trans_date_trans_time'].dt.time # extracts the time part from the 'trans_date_trans_time' datetime object and stores it in a new column called 'trans_time'.\n",
    "    return data # returns 2 new cols\n",
    "\n",
    "def dates_since_last_purchase(data):\n",
    "    # Days Since Last Purchase Per Card: Used to calculate the number of days between each transaction \n",
    "    # for the same credit card. Helps detect a pattern of how frequently the card is being used; for example, \n",
    "    # if the card is used 2-3 times a day and all of a sudden the card is being used 10 times a day for \n",
    "    # 2 days straight, it could be fraud.\n",
    "    # Ensure data is sorted by date for correct days calculation\n",
    "    data.sort_values(by=['cc_num', 'trans_date_trans_time'], inplace=True)\n",
    "    # Calculate the number of days between each transaction for the same credit card\n",
    "    data['days_since_last'] = data.groupby('cc_num')['trans_date_trans_time'].diff().dt.days.fillna(0).astype(int)\n",
    "    return data\n",
    "\n",
    "def convert_to_numerical_data(data):\n",
    "    # Convert 'trans_date_trans_time' to total seconds elapsed since midnight\n",
    "    data['trans_time_seconds'] = data['trans_date_trans_time'].dt.hour * 3600 + data['trans_date_trans_time'].dt.minute * 60 + data['trans_date_trans_time'].dt.second\n",
    "    \n",
    "    # Perform one-hot encoding for 'merchant' and 'category'\n",
    "    data = pd.get_dummies(data, columns=['merchant', 'category'])\n",
    "    \n",
    "    # Convert 'trans_date' to datetime and extract features\n",
    "    data['trans_date'] = pd.to_datetime(data['trans_date'])\n",
    "    data['trans_date_year'] = data['trans_date'].dt.year\n",
    "    data['trans_date_month'] = data['trans_date'].dt.month\n",
    "    data['trans_date_day'] = data['trans_date'].dt.day\n",
    "    # Convert 'trans_time' to total seconds elapsed since midnight\n",
    "    data['trans_time_seconds'] = data['trans_time'].apply(lambda x: x.hour * 3600 + x.minute * 60 + x.second)\n",
    "    # Drop the original non-numeric columns\n",
    "    data.drop(['trans_date_trans_time', 'trans_date', 'trans_time'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def drop_unnecessary_cols(data):\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'job', 'dob', 'trans_num', 'unix_time']\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data\n",
    "\n",
    "def separate_features_and_labels(data, label_column_name):\n",
    "    # Since 'is_fraud' is the label column, separate the features and labels\n",
    "    X = data.drop(label_column_name, axis=1)  # Drop the label column to create the features set\n",
    "    y = data[label_column_name]              # Get the label column as the labels set\n",
    "    return X, y\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = handle_date_time(data)\n",
    "    data = avg_trans_amt_per_card(data)\n",
    "    data = trans_freq_per_card(data)\n",
    "    data = dates_since_last_purchase(data)\n",
    "    data = change_in_spending(data)\n",
    "    data = convert_to_numerical_data(data)\n",
    "    data = drop_unnecessary_cols(data)\n",
    "    # data = split_features(data)\n",
    "    return data\n",
    "\n",
    "def scale_data(X_train, X_val):\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    # Fit the scaler only on the training data\n",
    "    scaler.fit(X_train)\n",
    "    # Apply the transformation to the training data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    # Apply the same transformation to the validation data\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154d6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('fraudTrain.csv')\n",
    "Y = pd.read_csv('fraudTest.csv')\n",
    "# Prep the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "Y = X['is_fraud']  # assuming 'is_fraud' is the target column\n",
    "X = X.drop(columns=['is_fraud'])\n",
    "X = preprocess_data(X)\n",
    "\n",
    "categorical_columns = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'trans_date_trans_time', 'dob', 'trans_num']\n",
    "# Performs One-Hot-Encoding on string data\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_columns)\n",
    "\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_columns)\n",
    "\n",
    "Y_train = pd.get_dummies(Y_train, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7bbb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0        cc_num     amt    zip      lat      long  city_pop  \\\n",
      "4677        4677  4.292744e+18   69.70  20634  38.2674  -76.4954      5927   \n",
      "800          800  3.560698e+15   47.28  92210  33.7163 -116.3381      4677   \n",
      "3671        3671  3.531130e+15   18.38   5733  43.8065  -73.0882      5895   \n",
      "4193        4193  6.011367e+15  243.23  17051  40.5046  -77.7186      4653   \n",
      "2968        2968  3.772340e+14    9.46  25442  39.3716  -77.8229      1925   \n",
      "...          ...           ...     ...    ...      ...       ...       ...   \n",
      "4426        4426  3.764450e+14    3.81  69165  41.1558 -101.1360      1789   \n",
      "466          466  4.951647e+15   45.67  62856  37.9943  -88.9417       324   \n",
      "3092        3092  4.365383e+15   97.81  55771  48.1439  -92.8561      1680   \n",
      "3772        3772  2.288814e+15   28.98  10039  40.8265  -73.9383   1577385   \n",
      "860          860  4.198470e+12    3.58  51521  41.4768  -95.3509      2036   \n",
      "\n",
      "       unix_time  merch_lat  merch_long  ...  \\\n",
      "4677  1371920961  38.735038  -77.401301  ...   \n",
      "800   1371833306  34.543180 -115.448531  ...   \n",
      "3671  1371903715  44.087314  -73.464019  ...   \n",
      "4193  1371912525  39.683505  -78.705316  ...   \n",
      "2968  1371886039  39.765552  -77.747955  ...   \n",
      "...          ...        ...         ...  ...   \n",
      "4426  1371916465  40.986227 -101.875263  ...   \n",
      "466   1371826517  37.122514  -88.328393  ...   \n",
      "3092  1371889235  47.286472  -93.212163  ...   \n",
      "3772  1371905662  39.987808  -73.016473  ...   \n",
      "860   1371834548  40.486739  -95.008421  ...   \n",
      "\n",
      "      trans_num_ff277328ef52e034054377011e166da0  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ff2e4b54a464dbb8025ea64c03edc875  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ff5994e47ce7f8ff5cdd5159ec2b4a32  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ff5cb4e3b110197becb0f612dd2b656c  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ff95d98a72d037860cf2b54185a6ef08  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ffa74f6fc350885149927108089ab1c8  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ffb96d3fc087f628d14a722f35a7b735  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ffc9db75cc5998ccd5e2d555786e26e5  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_ffd6d0012990c75f4f01d4fcad349e75  \\\n",
      "4677                                       False   \n",
      "800                                        False   \n",
      "3671                                       False   \n",
      "4193                                       False   \n",
      "2968                                       False   \n",
      "...                                          ...   \n",
      "4426                                       False   \n",
      "466                                        False   \n",
      "3092                                       False   \n",
      "3772                                       False   \n",
      "860                                        False   \n",
      "\n",
      "      trans_num_fff6a1c304254d596afe32e06e2a8a61  \n",
      "4677                                       False  \n",
      "800                                        False  \n",
      "3671                                       False  \n",
      "4193                                       False  \n",
      "2968                                       False  \n",
      "...                                          ...  \n",
      "4426                                       False  \n",
      "466                                        False  \n",
      "3092                                       False  \n",
      "3772                                       False  \n",
      "860                                        False  \n",
      "\n",
      "[4000 rows x 10111 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_train)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodelC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m modelR\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:665\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    663\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight_is_none:\n\u001b[0;32m--> 665\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_y(y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:1500\u001b[0m, in \u001b[0;36mGradientBoostingClassifier._encode_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, sample_weight):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;66;03m# encode classes into 0 ... n_classes - 1 and sets attributes classes_\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;66;03m# and n_trees_per_iteration_\u001b[39;00m\n\u001b[0;32m-> 1500\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m     label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m   1503\u001b[0m     encoded_y_int \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# Initialize Models\n",
    "# For classification\n",
    "modelC = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "# For regression\n",
    "modelR = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "print(Y_train)\n",
    "# Train models\n",
    "modelC.fit(X_train, Y_train)\n",
    "modelR.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions_R = modelR.predict(X_test)\n",
    "predictions_C = modelC.predict(X_test)\n",
    "\n",
    "# For classification\n",
    "accuracy = accuracy_score(Y_test, predictions_C)\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n",
    "mse = mean_squared_error(Y_test, predictions_R)\n",
    "print(f\" Classification Mean Squared Error: {mse}\")\n",
    "\n",
    "# For regression\n",
    "mse = mean_squared_error(Y_test, predictions_R)\n",
    "print(f\"Regression Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036f9b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "new_predictions = model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
